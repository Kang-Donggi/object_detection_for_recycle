{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my_albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_aug.albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_aug.albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch.transforms import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import PIL\n",
    "from torchvision.utils import save_image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('/home/kangdg22/meta_Assignment/boostcamp/detection/coco_dataset/train.json', 'r') as f:\n",
    "#     json_data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_id=8\n",
    "\n",
    "# filtered_annotations = [annotation for annotation in json_data['annotations'] if annotation['category_id'] == category_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list=sorted(glob('/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/original_train/*txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dir='/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/battery_data'\n",
    "cnt=0\n",
    "bettry_list=[]\n",
    "for i in txt_list:\n",
    "    with open(i, 'r') as txt:\n",
    "        lines=txt.readlines()\n",
    "        for j in lines:\n",
    "            if int(j[0])==0:\n",
    "                bettry_list.append(f'/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/original_train/{os.path.basename(i)[:-3]}jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복제거\n",
    "bettry_img=sorted(list(set(bettry_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt list 생성\n",
    "bettry_txt=[]\n",
    "for i in bettry_img:\n",
    "    bettry_txt.append(i[:-3]+'txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, anno_path):\n",
    "    image=np.array(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "    with open(anno_path, 'r') as f:\n",
    "        lines=f.readlines()\n",
    "        boxes=[]\n",
    "        \n",
    "    for line in lines:\n",
    "        bbox_info = line.split()  \n",
    "        class_label = int(bbox_info[0])\n",
    "        coordinates = list(map(float, bbox_info[1:]))\n",
    "  \n",
    "        bounding_box = coordinates + [class_label]  \n",
    "        boxes.append(bounding_box)\n",
    "        \n",
    "\n",
    "    return image, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def albumen(image, bboxes):\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        A.VerticalFlip(p=0.7),\n",
    "        A.Rotate(limit=60, p=0.7),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.3,0.3), p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 11), p=0.2),\n",
    "        A.Affine (scale=(0.5, 1.0), shear=(-0.7,0.7), p=0.7),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='yolo'))\n",
    "\n",
    "    augmented=transform(image=image, bboxes=bboxes)\n",
    "    \n",
    "  \n",
    "    \n",
    "    return augmented['image'], augmented['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, txt) in enumerate(zip(bettry_img, bettry_txt)):\n",
    "    image, bbox=load_data(img, txt)\n",
    "    augmented_img, augmented_bbox=albumen(image, bbox)\n",
    "    # bbox = [[t[0], t[1], t[2],t[3], t[4]] for t in augmented_bbox]\n",
    "    \n",
    "    # for j in range(len(bbox)):\n",
    "    #     for k in range(4):\n",
    "    #         if bbox[j][k]<0:\n",
    "    #             bbox[j][k]=0\n",
    "    #         elif bbox[j][k]>1:\n",
    "    #             bbox[j][k]=1\n",
    "\n",
    "    tran=transforms.ToPILImage()\n",
    "    save_img=tran(augmented_img)\n",
    "    save_img.save(f'/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/general_trash/{8989+(i+1)}.jpg')\n",
    "    # save_image(augmented_img, f'/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/bettry_data/{4882+(i+1)}.jpg')\n",
    "    modified_data = [(t[-1], *t[:-1]) for t in augmented_bbox]\n",
    "    with open(f'/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/general_trash/{8989+(i+1)}.txt', 'w') as file:\n",
    "        for item in modified_data:\n",
    "            line=' '.join(map(str, item))\n",
    "            file.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_data = [(t[-1], *t[:-1]) for t in augmented_bounding_boxes]\n",
    "\n",
    "# with open('/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/aug_bbox.txt', 'w') as file:\n",
    "#     for item in modified_data:\n",
    "#         line=' '.join(map(str, item))\n",
    "#         file.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/train/0000.txt', 'r') as file:\n",
    "#     line=file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path='/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/battery_data/4883.jpg'\n",
    "bbox_path='/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/battery_data/4883.txt'\n",
    "\n",
    "                \n",
    "\n",
    "image, bounding_boxes = load_data(img_path, bbox_path)\n",
    "# bounding_boxes\n",
    "# bbox=[list(t) for t in bounding_boxes]\n",
    "\n",
    "augmented_image, augmented_bounding_boxes = albumen(image, bounding_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 원본이미지 확인\n",
    "# PIL.Image.open(img_path)\n",
    "\n",
    "# 변환이미지 확인\n",
    "# test_per=augmented_image.permute(1,2,0)\n",
    "# plt.imshow(test_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding box 시각화 \n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_bbox(aug_img, bbox_list):\n",
    "    aug_img=aug_img.permute(1,2,0)\n",
    "\n",
    "    fig, ax=plt.subplots(1)\n",
    "    ax.imshow(aug_img)\n",
    "    \n",
    "    for bbox in bbox_list:\n",
    "        class_label=int(bbox[-1])\n",
    "        x,y,w,h=bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "\n",
    "        x_abs, y_abs=x*aug_img.shape[1], y*aug_img.shape[0]\n",
    "        w_abs, h_abs=w*aug_img.shape[1], h*aug_img.shape[0]\n",
    "\n",
    "        rect = patches.Rectangle((x_abs - w_abs / 2, y_abs - h_abs / 2), w_abs, h_abs,\n",
    "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
    "        \n",
    "        ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_bbox(augmented_image, augmented_bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/styroform_2/* /home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/split/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/over_train2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil \n",
    "from_file_path = '/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/over_train' \n",
    "to_file_path = '/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/over_train2' \n",
    "shutil.copytree(from_file_path, to_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "a=glob('/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/general_trash/*.txt')\n",
    "for i in a:\n",
    "    shutil.copy(i, f'/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/over_train2/{os.path.basename(i)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "for i in range(9290, 9690):\n",
    "    shutil.copy(f'/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/general_trash/{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4826"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "infer_txt=sorted(glob('/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_code/train_yolo_scale0.5/predict/labels/*.txt'))\n",
    "len(infer_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(infer_txt[0][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for i in range(8990, 11094):\n",
    "    shutil.copy(f'/home/kangdg22/meta_Assignment/boostcamp/detection/preprocessing/general_trash/{i}.txt', f'/home/kangdg22/meta_Assignment/boostcamp/detection/yolo_dataset/split copy/train/{i}.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
